{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Test1_J054.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narayananv10/DeepLearning/blob/master/DL_Test1_J054.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y6AZyfZvc00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgNJgA7IwJCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhlVDlQSxRM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eI6y3ssxJuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMfaBL1qxV7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEuVP_I_xeVg",
        "colab_type": "code",
        "outputId": "66a62a14-1efa-4eeb-c756-80307648b976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.2231 - acc: 0.9318 - val_loss: 0.0952 - val_acc: 0.9698\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0830 - acc: 0.9748 - val_loss: 0.0869 - val_acc: 0.9727\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0552 - acc: 0.9833 - val_loss: 0.0675 - val_acc: 0.9812\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0386 - acc: 0.9877 - val_loss: 0.0877 - val_acc: 0.9763\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0745 - val_acc: 0.9816\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0227 - acc: 0.9928 - val_loss: 0.0911 - val_acc: 0.9803\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0170 - acc: 0.9949 - val_loss: 0.0903 - val_acc: 0.9802\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0864 - val_acc: 0.9832\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.1190 - val_acc: 0.9765\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0103 - acc: 0.9970 - val_loss: 0.0992 - val_acc: 0.9819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa9e4beb4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFb1UNYHyf9y",
        "colab_type": "code",
        "outputId": "54c4642e-bded-490a-ab5e-2343d191e2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.09921407518272654\n",
            "Test accuracy: 0.9819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywy6l406xkRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6MDkDCcyPQK",
        "colab_type": "code",
        "outputId": "05d2a1aa-ce35-4419-fb52-6a8eb557621c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0869 - val_acc: 0.9848\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0856 - val_acc: 0.9850\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0848 - val_acc: 0.9849\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0843 - val_acc: 0.9850\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0838 - val_acc: 0.9849\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0835 - val_acc: 0.9850\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0832 - val_acc: 0.9852\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 9.9024e-04 - acc: 0.9999 - val_loss: 0.0831 - val_acc: 0.9851\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 9.3581e-04 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9852\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 8.9123e-04 - acc: 1.0000 - val_loss: 0.0827 - val_acc: 0.9850\n",
            "Test loss: 0.08271434506483481\n",
            "Test accuracy: 0.985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b707lZ1fyuci",
        "colab_type": "code",
        "outputId": "555be9fe-ca8e-4897-940f-f128627013fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 8.5344e-04 - acc: 1.0000 - val_loss: 0.0826 - val_acc: 0.9850\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 8.2192e-04 - acc: 1.0000 - val_loss: 0.0825 - val_acc: 0.9850\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 7.9461e-04 - acc: 1.0000 - val_loss: 0.0824 - val_acc: 0.9850\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 7.7097e-04 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 0.9851\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 7.5007e-04 - acc: 1.0000 - val_loss: 0.0822 - val_acc: 0.9850\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 7.3163e-04 - acc: 1.0000 - val_loss: 0.0821 - val_acc: 0.9850\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 7.1477e-04 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9852\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.9974e-04 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9853\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.8591e-04 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9852\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.7345e-04 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa9e5e98f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMduoiTfzJU_",
        "colab_type": "code",
        "outputId": "893c7326-9118-4cad-e9fc-aab89f2d1965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 39us/step\n",
            "Test loss: 0.08188596225263707\n",
            "Test accuracy: 0.9852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1TTVi-v0rpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd=optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRS6PRRq2hBN",
        "colab_type": "code",
        "outputId": "8adc06e3-1a85-4f65-da38-58ee91a63dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 6.6190e-04 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 0.9852\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.5116e-04 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 0.9852\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.4118e-04 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 0.9851\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.3202e-04 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 0.9852\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.2349e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.1537e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9852\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.0808e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9852\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.0106e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9852\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 5.9446e-04 - acc: 1.0000 - val_loss: 0.0816 - val_acc: 0.9851\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 5.8832e-04 - acc: 1.0000 - val_loss: 0.0816 - val_acc: 0.9850\n",
            "Test loss: 0.08164481767864097\n",
            "Test accuracy: 0.985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BATUnBri4xee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLzh_VSI42CR",
        "colab_type": "code",
        "outputId": "2303b5cf-869c-4de9-95e3-2739b0dff933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.1102 - val_acc: 0.9818\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.1108 - val_acc: 0.9825\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.1264 - val_acc: 0.9798\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.1025 - val_acc: 0.9841\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.1336 - val_acc: 0.9823\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.1498 - val_acc: 0.9805\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.1239 - val_acc: 0.9834\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.1227 - val_acc: 0.9832\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.1250 - val_acc: 0.9838\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1430 - val_acc: 0.9818\n",
            "Test loss: 0.14304742624076058\n",
            "Test accuracy: 0.9818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVFbLx0N48xR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPwpp_fi49tE",
        "colab_type": "code",
        "outputId": "0ab3998c-ac6f-4725-f8af-592a5c6c79e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0279 - acc: 0.9958 - val_loss: 0.1172 - val_acc: 0.9846\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 7.9018e-04 - acc: 0.9998 - val_loss: 0.1174 - val_acc: 0.9846\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 3.0464e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9848\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.9017e-04 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9847\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8665e-04 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9848\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8452e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9848\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8301e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9848\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8186e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9848\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8093e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9848\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8016e-04 - acc: 1.0000 - val_loss: 0.1153 - val_acc: 0.9848\n",
            "Test loss: 0.11533341809495434\n",
            "Test accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM5WLTOW5Cmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHd-21ts5FKU",
        "colab_type": "code",
        "outputId": "503472a7-c5d0-4b5d-c803-e5231757ead2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 2.7953e-04 - acc: 1.0000 - val_loss: 0.1153 - val_acc: 0.9848\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7792e-04 - acc: 1.0000 - val_loss: 0.1153 - val_acc: 0.9847\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7686e-04 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9849\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7603e-04 - acc: 1.0000 - val_loss: 0.1153 - val_acc: 0.9848\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7544e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9849\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7494e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9848\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7451e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9847\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7415e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9848\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7384e-04 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9849\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7358e-04 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9848\n",
            "Test loss: 0.11572609617474051\n",
            "Test accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fa2CMd95J8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4I6GTWO5McV",
        "colab_type": "code",
        "outputId": "95198993-fb01-413b-90c0-e49a3256af3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0197 - acc: 0.9953 - val_loss: 0.1364 - val_acc: 0.9799\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0107 - acc: 0.9970 - val_loss: 0.1307 - val_acc: 0.9799\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.1292 - val_acc: 0.9796\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0132 - acc: 0.9961 - val_loss: 0.0988 - val_acc: 0.9839\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.1101 - val_acc: 0.9815\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.1142 - val_acc: 0.9818\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0105 - acc: 0.9971 - val_loss: 0.1266 - val_acc: 0.9783\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0088 - acc: 0.9972 - val_loss: 0.1383 - val_acc: 0.9761\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0112 - acc: 0.9965 - val_loss: 0.1113 - val_acc: 0.9816\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.1047 - val_acc: 0.9817\n",
            "Test loss: 0.10472515965971078\n",
            "Test accuracy: 0.9817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3ZrAF0u5P61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZLirsb85TbG",
        "colab_type": "code",
        "outputId": "2da5500e-e856-4dd2-d42a-b72f3c350842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1006 - val_acc: 0.9846\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 3.1955e-04 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9853\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.8389e-04 - acc: 1.0000 - val_loss: 0.0997 - val_acc: 0.9855\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.7889e-04 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9855\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7565e-04 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9856\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7330e-04 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9856\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.7172e-04 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9857\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7065e-04 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9858\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.6998e-04 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9858\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6947e-04 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9857\n",
            "Test loss: 0.10970291562096675\n",
            "Test accuracy: 0.9857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mh7dRds5XND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-amfDex5aaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLm5wKw12jwH",
        "colab_type": "code",
        "outputId": "aa6c55e4-09d7-4e3e-f607-cfd531081d02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0312 - acc: 0.9925 - val_loss: 0.1225 - val_acc: 0.9783\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0258 - acc: 0.9931 - val_loss: 0.1179 - val_acc: 0.9793\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0218 - acc: 0.9939 - val_loss: 0.1251 - val_acc: 0.9793\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0176 - acc: 0.9946 - val_loss: 0.1196 - val_acc: 0.9796\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.1193 - val_acc: 0.9783\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.1133 - val_acc: 0.9819\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0179 - acc: 0.9951 - val_loss: 0.1173 - val_acc: 0.9807\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0209 - acc: 0.9946 - val_loss: 0.1142 - val_acc: 0.9788\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0120 - acc: 0.9969 - val_loss: 0.1385 - val_acc: 0.9775\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0143 - acc: 0.9961 - val_loss: 0.1179 - val_acc: 0.9822\n",
            "Test loss: 0.11794245182841472\n",
            "Test accuracy: 0.9822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqvveNjM5kEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-3n_Wb550Ub",
        "colab_type": "code",
        "outputId": "7124f45c-089c-48e8-ffe6-babf3475d994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.1062 - val_acc: 0.9846\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 4.3309e-04 - acc: 0.9999 - val_loss: 0.1081 - val_acc: 0.9845\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 3.2567e-04 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9844\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 3.0612e-04 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9843\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.9410e-04 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9843\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.8580e-04 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9842\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7994e-04 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9846\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7597e-04 - acc: 1.0000 - val_loss: 0.1126 - val_acc: 0.9845\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7334e-04 - acc: 1.0000 - val_loss: 0.1137 - val_acc: 0.9846\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.7162e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9848\n",
            "Test loss: 0.11536230263116497\n",
            "Test accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0PecmfD55Yn",
        "colab_type": "code",
        "outputId": "e5366c3d-d34d-4f9d-9aad-049d1460305a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncZiZWUmcOMzMrCROHGZmVpL/D9dky0T8EBfHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAfTElEQVR4nO3de5hddX3v8fcnM5nJ5B4m4ZJMSGJA\nJYgVHOMFjyggghfSHkESDwoxNqVPEXuobeM5fUSibcHHihTSY6OEclEjDXJMqzSCtD0qCpmECIZA\niYHAhKCTyQ1yn8z3/LHWZPbs+U0yk8zOnmR/Xs8zz16X31r7uzfk99lr/dZeWxGBmZlZsUHlLsDM\nzAYmB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmSA8LsCEiaLCkkVfei7dWSfnak+zE7WhwQVjEk\nvSBpr6SxRcufyDvnyeWpzGxgckBYpXkemNUxI+ksYGj5yjEbuBwQVmnuAT5ZMH8VcHdhA0mjJN0t\nqUXSekl/JWlQvq5K0lclbZK0DvhQYts7JG2UtEHSlyVV9bVISeMlLZW0WdJaSX9YsG66pCZJ2yX9\nVtLX8uVDJN0rqVXSVknLJZ3U1+c26+CAsErzS2CkpDPyjnsmcG9Rm9uAUcDrgPPIAmV2vu4PgQ8D\nZwONwGVF2/4T0Aaclre5CPj0YdS5GGgGxufP8TeSzs/X3QrcGhEjganAffnyq/K6JwL1wDXArsN4\nbjPAAWGVqeMo4v3AGmBDx4qC0Ph8RLwaES8Afwd8Im/yMeDrEfFSRGwG/rZg25OADwJ/GhE7IuJ3\nwC35/npN0kTgXOAvI2J3RKwCvkXnkc8+4DRJYyPitYj4ZcHyeuC0iNgfESsiYntfntuskAPCKtE9\nwMeBqyk6vQSMBQYD6wuWrQcm5NPjgZeK1nWYlG+7MT/FsxX4R+DEPtY3HtgcEa/2UMMc4PXAM/lp\npA8XvK5lwGJJL0v6iqTBfXxuswMcEFZxImI92WD1B4HvF63eRPZJfFLBslPpPMrYSHYKp3Bdh5eA\nPcDYiBid/42MiDP7WOLLwAmSRqRqiIjnImIWWfDcDCyRNCwi9kXEjRExDXgX2amwT2J2mBwQVqnm\nAOdHxI7ChRGxn+yc/l9LGiFpEnA9neMU9wHXSWqQNAaYV7DtRuDHwN9JGilpkKSpks7rS2ER8RLw\nKPC3+cDzm/N67wWQdKWkcRHRDmzNN2uX9D5JZ+WnybaTBV17X57brJADwipSRPwmIpp6WP0ZYAew\nDvgZ8B1gUb7um2SncX4FrKT7EcgngRrgaWALsAQ45TBKnAVMJjuaeAC4ISIeztddDKyW9BrZgPXM\niNgFnJw/33aysZX/JDvtZHZY5B8MMjOzFB9BmJlZkgPCzMySHBBmZpZU0oCQdLGkZ/NbBcxLrH+P\npJWS2iRdVrD8LZJ+IWm1pCclXVHKOs3MrLuSDVLnl9r9F9m3VZuB5cCsiHi6oM1kYCTwOWBpRCzJ\nl78eiIh4TtJ4YAVwRkRspQdjx46NyZMnl+S1mJkdr1asWLEpIsal1pXy3vPTgbURsQ5A0mJgBtnl\nfwDktzFAUpdrtSPivwqmX5b0O2Acndd8dzN58mSamnq6atHMzFIkre9pXSlPMU2g6y0Jmum8VUCv\nSZpOdl35bxLr5uZ3tWxqaWk57ELNzKy7AT1ILekUsi/6zM6/NdpFRCyMiMaIaBw3LnmEZGZmh6mU\nAbGBrvesaaDgrpmHImkk8EPgfxfcrdLMzI6SUo5BLAdOlzSFLBhmkt1B85Ak1ZDdXuDujoHrw7Fv\n3z6am5vZvXv34e7imDNkyBAaGhoYPNg38TSzI1OygIiINknXkt23pgpYFBGrJc0HmiJiqaS3kQXB\nGOAjkm7M73z5MeA9QL2kq/NdXp3fF7/XmpubGTFiBJMnT0ZSf720ASsiaG1tpbm5mSlTppS7HDM7\nxpXyCIKI+BHwo6JlXyiYXk526ql4u3vp/itffbZ79+6KCQcASdTX1+MBezPrDwN6kLo/VEo4dKi0\n12tmpVPSIwgzM+snEbB3B+xogZ2t2eOOTdlj3RhonH3offSRA6KEWltbueCCCwB45ZVXqKqqouNy\n3Mcff5yamppD7mP27NnMmzePN7zhDSWt1czKYO/OvMPflHf2m3qYzwOhrYcLbhre5oA41tTX17Nq\nVTau/sUvfpHhw4fzuc99rkubiCAiGDQofbbvzjvvLHmdZtZP9u3KOvVDdvj59L6d6f1UD4Fh42Bo\nffZ44hmd08PG5uvG5tNjoWZYSV6OA6IM1q5dy6WXXsrZZ5/NE088wUMPPcSNN97IypUr2bVrF1dc\ncQVf+EI2lv/ud7+b22+/nTe96U2MHTuWa665hgcffJChQ4fygx/8gBNPPLHMr8bsOLK/Dfa+Cru3\nw55X8798eve27st2be3a4e99Lb3fqpquHf7Y07vOH+j08/maYTAAxhMrJiBu/JfVPP3y9n7d57Tx\nI7nhI339PfrMM888w913301jYyMAN910EyeccAJtbW28733v47LLLmPatGldttm2bRvnnXceN910\nE9dffz2LFi1i3rxuN8k1qzzt7VnnXNh579le0NEXdPi7t+fz2wvm83X7dhz6uTQIakdmf0NGZZ37\nCVMO3uHXjhgQHX5fVUxADDRTp049EA4A3/3ud7njjjtoa2vj5Zdf5umnn+4WEHV1dVxyySUAvPWt\nb+WnP/3pUa3Z7IhEZKdg9u3KOuJ9u7JTLHt3dl22d0f3dsXL9u7s3vFzqDtTK+uoa0fkHfwIGDIa\nRp9asKxj+cielw0eekx29oejYgLicD/pl8qwYZ3nDJ977jluvfVWHn/8cUaPHs2VV16Z/PZ34aB2\nVVUVbW1tR6VWq0AR2SfyXVth91bYtSWf3pZ31jvzv8JOPrWsKAz6qqoGBtdlnXLHX03+N+LkHjr0\n/LF4Wc1w6GGsz9IqJiAGsu3btzNixAhGjhzJxo0bWbZsGRdffHG5y7JjXccn9t1bs85915bO6S6d\nfvF0/th+qA8gys6Vd+nA67Jlw8bB6MJlQ7t28qllNUO776vKt4wpJwfEAHDOOecwbdo03vjGNzJp\n0iTOPffccpdkA0F7e3ZZY9tuaNuTnU4p7sgP1env33uQJxDUjc5Os3Q8jj61YNmYxPSo7JP44KFQ\nXVsxp1oqVcl+Ue5oa2xsjOIfDFqzZg1nnHFGmSoqn0p93f0uIuuYOzro5OPuxPyhtjnE4758P+37\neldn7cjOTv6gnXtHmzHZdO1In3IxJK2IiMbUOh9B2MAVkX0CPmQHfZAOd9+uw++o9+858tdQVZtd\n015dC4OHdE5X59N1Y4qWHeSxdmTe0Y/p7OhrR0KV/xlbafj/LDsy7fsLBiR3dA5W7t3ROZh54LGw\nTVHb1D727eLQV6YcQtUhOt4how7RMddAdV1ieS869aoaf0K3Y5oDYqCIgGjPHjs6xQPTkS8qni5o\nc+BUYT4w+fRSiP1ZB96+PxtwjPyxY1lP8/v3JTr5Hjr1nr7635NBg/PByGGdg5Q1w7JTHiMn5IOe\n+YBldV36U3dvPm1X17mDNjtCDohSi+jsdA887it4bOucP9JPyx12tMCyTxzmxsquHOnouA9cXTIs\n+2r/6ETnXtim8LFmWPe2virF7JjhgDhc0d61cy/u7AvnU1SVdZaDqrOOc9Dg/Fyy8itD8qtD+jLd\ncUXJ5kFwzc+yfasKBnX8dcxXdy4rnFeVP3Gb2QEOiGLt+xOf9BPzPV0jPqi6s7Ovzq/jHjS4Mww6\n5kvZEVfVwMm+isnMjowDYv8+2PJCZ8cf+xON1Nm5V9V2nirp1vFXZ/dpybW2tnLB+47sdt8AixYt\n4oMf/CAnn3zykb5aM7Nec0BoEBCd39os/JTfMT+o+rC+ENSb2333xqJFizjnnHMcEGZ2VDkgBlXB\n2Ncf9ae96667WLBgAXv37uVd73oXt99+O+3t7cyePZtVq1YREcydO5eTTjqJVatWccUVV1BXV9en\nIw8zsyNROQHx4Dx45an+3efJZ8ElN/V5s1//+tc88MADPProo1RXVzN37lwWL17M1KlT2bRpE089\nldW5detWRo8ezW233cbtt9/OW97ylv6t38zsIConIAaQhx9+mOXLlx+43feuXbuYOHEiH/jAB3j2\n2We57rrr+NCHPsRFF11U5krNrJJVTkAcxif9UokIPvWpT/GlL32p27onn3ySBx98kAULFnD//fez\ncOHCMlRoZga+6L0MLrzwQu677z42bdoEZFc7vfjii7S0tBARXH755cyfP5+VK1cCMGLECF599dVy\nlmxmFahyjiAGkLPOOosbbriBCy+8kPb2dgYPHsw3vvENqqqqmDNnDhGBJG6++WYAZs+ezac//WkP\nUpvZUVXS231Luhi4FagCvhURNxWtfw/wdeDNwMyIWFKw7irgr/LZL0fEXQd7Lt/uu1Olvm4z67uD\n3e67ZKeYJFUBC4BLgGnALEnTipq9CFwNfKdo2xOAG4C3A9OBGySNKVWtZmbWXSnHIKYDayNiXUTs\nBRYDMwobRMQLEfEk0F607QeAhyJic0RsAR4C/BucZmZHUSkDYgLwUsF8c76s1Nt2cbz8Yl5vVdrr\nNbPSOaavYpI0V1KTpKaWlpZu64cMGUJra2vFdJoRQWtrK0OGDCl3KWZ2HCjlVUwbgIkF8w35st5u\n+96ibf+juFFELAQWQjZIXby+oaGB5uZmUuFxvBoyZAgNDQ3lLsPMjgOlDIjlwOmSppB1+DOBj/dy\n22XA3xQMTF8EfL6vBQwePJgpU6b0dTMzM6OEp5giog24lqyzXwPcFxGrJc2XdCmApLdJagYuB/5R\n0up8283Al8hCZjkwP19mZmZHSUm/B3E0pb4HYWZmB1eW70GYmdmxzQFhZmZJDggzM0tyQJiZWZID\nwszMkhwQZmaW5IAwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmSA8LMzJIcEGZmluSAMDOz\nJAeEmZklOSDMzCzJAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJTkgzMwsyQFh\nZmZJJQ0ISRdLelbSWknzEutrJX0vX/+YpMn58sGS7pL0lKQ1kj5fyjrNzKy7kgWEpCpgAXAJMA2Y\nJWlaUbM5wJaIOA24Bbg5X345UBsRZwFvBf6oIzzMzOzoKOURxHRgbUSsi4i9wGJgRlGbGcBd+fQS\n4AJJAgIYJqkaqAP2AttLWKuZmRUpZUBMAF4qmG/OlyXbREQbsA2oJwuLHcBG4EXgqxGxufgJJM2V\n1CSpqaWlpf9fgZlZBRuog9TTgf3AeGAK8GeSXlfcKCIWRkRjRDSOGzfuaNdoZnZcK2VAbAAmFsw3\n5MuSbfLTSaOAVuDjwL9FxL6I+B3wc6CxhLWamVmRUgbEcuB0SVMk1QAzgaVFbZYCV+XTlwGPRESQ\nnVY6H0DSMOAdwDMlrNXMzIqULCDyMYVrgWXAGuC+iFgtab6kS/NmdwD1ktYC1wMdl8IuAIZLWk0W\nNHdGxJOlqtXMzLpT9oH92NfY2BhNTU3lLsPM7JgiaUVEJE/hD9RBajMzKzMHhJmZJTkgzMwsyQFh\nZmZJDggzM0tyQJiZWZIDwszMkhwQZmaW5IAwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmS\nA8LMzJIcEGZmluSAMDOzJAeEmZklOSDMzCzJAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbUq4CQ\nNFVSbT79XknXSRpd2tLMzKycensEcT+wX9JpwEJgIvCdQ20k6WJJz0paK2leYn2tpO/l6x+TNLlg\n3Zsl/ULSaklPSRrSy1rNzKwf9DYg2iOiDfgD4LaI+HPglINtIKkKWABcAkwDZkmaVtRsDrAlIk4D\nbgFuzretBu4FromIM4H3Avt6WauZmfWD3gbEPkmzgKuAf82XDT7ENtOBtRGxLiL2AouBGUVtZgB3\n5dNLgAskCbgIeDIifgUQEa0Rsb+XtZqZWT/obUDMBt4J/HVEPC9pCnDPIbaZALxUMN+cL0u2yY9Q\ntgH1wOuBkLRM0kpJf5F6AklzJTVJamppaenlSzEzs96o7k2jiHgauA5A0hhgRETcXOK63g28DdgJ\n/ETSioj4SVFdC8nGRGhsbIwS1mNmVnF6exXTf0gaKekEYCXwTUlfO8RmG8gGszs05MuSbfJxh1FA\nK9nRxv+LiE0RsRP4EXBOb2o1M7P+0dtTTKMiYjvw34G7I+LtwIWH2GY5cLqkKZJqgJnA0qI2S8nG\nNQAuAx6JiACWAWdJGpoHx3nA072s1czM+kFvA6Ja0inAx+gcpD6ofEzhWrLOfg1wX0SsljRf0qV5\nszuAeklrgeuBefm2W4CvkYXMKmBlRPywl7WamVk/6NUYBDCfrKP/eUQsl/Q64LlDbRQRPyI7PVS4\n7AsF07uBy3vY9l6yS13NzKwMejtI/c/APxfMrwM+WqqizMys/Ho7SN0g6QFJv8v/7pfUUOrizMys\nfHo7BnEn2YDy+PzvX/JlZmZ2nOptQIyLiDsjoi3/+ydgXAnrMjOzMuttQLRKulJSVf53Jdn3FczM\n7DjV24D4FNklrq8AG8m+s3B1iWoyM7MBoFcBERHrI+LSiBgXESdGxO/jq5jMzI5rR/KLctf3WxVm\nZjbgHElAqN+qMDOzAedIAsJ3TzUzO44d9JvUkl4lHQQC6kpSkZmZDQgHDYiIGHG0CjEzs4HlSE4x\nmZnZccwBYWZmSQ4IMzNLckCYmVmSA8LMzJIcEGZmluSAMDOzJAeEmZklOSDMzCzJAWFmZkkOCDMz\nS3JAmJlZkgPCzMySHBBmZpZU0oCQdLGkZyWtlTQvsb5W0vfy9Y9Jmly0/lRJr0n6XCnrNDOz7koW\nEJKqgAXAJcA0YJakaUXN5gBbIuI04Bbg5qL1XwMeLFWNZmbWs1IeQUwH1kbEuojYCywGZhS1mQHc\nlU8vAS6QJABJvw88D6wuYY1mZtaDUgbEBOClgvnmfFmyTUS0AduAeknDgb8EbjzYE0iaK6lJUlNL\nS0u/FW5mZgN3kPqLwC0R8drBGkXEwohojIjGcePGHZ3KzMwqxEF/k/oIbQAmFsw35MtSbZolVQOj\ngFbg7cBlkr4CjAbaJe2OiNtLWK+ZmRUoZUAsB06XNIUsCGYCHy9qsxS4CvgFcBnwSEQE8N86Gkj6\nIvCaw8HM7OgqWUBERJuka4FlQBWwKCJWS5oPNEXEUuAO4B5Ja4HNZCFiZmYDgLIP7Me+xsbGaGpq\nKncZZmbHFEkrIqIxtW6gDlKbmVmZOSDMzCzJAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAz\nsyQHhJmZJTkgzMwsyQFhZmZJDggzM0tyQJiZWZIDwszMkhwQZmaW5IAwM7MkB4SZmSU5IMzMLMkB\nYWZmSQ4IMzNLckCYmVmSA8LMzJIcEGZmluSAMDOzJAeEmZkllTQgJF0s6VlJayXNS6yvlfS9fP1j\nkibny98vaYWkp/LH80tZp5mZdVeygJBUBSwALgGmAbMkTStqNgfYEhGnAbcAN+fLNwEfiYizgKuA\ne0pVp5mZpZXyCGI6sDYi1kXEXmAxMKOozQzgrnx6CXCBJEXEExHxcr58NVAnqbaEtZqZWZFSBsQE\n4KWC+eZ8WbJNRLQB24D6ojYfBVZGxJ7iJ5A0V1KTpKaWlpZ+K9zMzAb4ILWkM8lOO/1Ran1ELIyI\nxohoHDdu3NEtzszsOFfKgNgATCyYb8iXJdtIqgZGAa35fAPwAPDJiPhNCes0M7OEUgbEcuB0SVMk\n1QAzgaVFbZaSDUIDXAY8EhEhaTTwQ2BeRPy8hDWamVkPShYQ+ZjCtcAyYA1wX0SsljRf0qV5szuA\neklrgeuBjkthrwVOA74gaVX+d2KpajUzs+4UEeWuoV80NjZGU1NTucswMzumSFoREY2pdQN6kNrM\nzMrHAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJTkgzMwsyQFhZmZJDggzM0ty\nQJiZWZIDwszMkhwQZmaW5IAwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmSA8LMzJIcEGZm\nllRd7gLKbfe+/fzBPzzKqSfUMbl+GKfWD2XSCcOYVD+U8aPrqBqkcpdoZlYWFR8Qr+1pY/yoIfym\nZQf//mwLe9vaD6wbXCUmjhmah8ZQJtVnwTGpfhgTT6ijtrqqjJWbmZVWxQfE2OG13HH12wBobw9e\n2b6b9a07Wd+6g/Wb88fWnax4YQuv7mk7sJ0Ep4wcciA0Tq0fmh2BnDCUSfVDGTFkcLlekplZvyhp\nQEi6GLgVqAK+FRE3Fa2vBe4G3gq0AldExAv5us8Dc4D9wHURsayUtQIMGiTGj65j/Og63jm1vsu6\niGDzjr2s37yTF1t38kLrjgOPD6/5LZte29ulff2wmm6h0REm9cNqkHzqyswGtpIFhKQqYAHwfqAZ\nWC5paUQ8XdBsDrAlIk6TNBO4GbhC0jRgJnAmMB54WNLrI2J/qeo9FEnUD6+lfngt55w6ptv61/a0\nsf5AaOzkxc3Zkcfjz2/m/67aQERn2+G11d1CY9IJQ2kYM5Sa6kFIoPw5O6YHdUwnlg3Kw6Zjuri9\nmdnhKOURxHRgbUSsA5C0GJgBFAbEDOCL+fQS4HZlPdoMYHFE7AGel7Q2398vSljvERleW82Z40dx\n5vhR3dbtadtP85ZdB05XdZzCeva3r/Lwmt+yb38k9th/uoUMHeHRGSiFwdMx3WUf3fapg67veN6D\n7eVQz5HeR1Z/Sk9ZmN5v74Ozrxnbl/Y9vZZ+qaMvbfvyfvStjJLtZKB89BkIH8LOOGUkt806u9/3\nW8qAmAC8VDDfDLy9pzYR0SZpG1CfL/9l0bYTip9A0lxgLsCpp57ab4X3t9rqKqaOG87UccO7rdvf\nHmzctov1rTvZsHUX+9uD9ggiIMhObUXQ8zI4ME2+rj3osp6OZXSuC/L9RXpZoeL4KlpNdGuRanPw\n9d1bpNqkl/VUQ4/7SO+ih7Z9DO8+NO/Lnov/m/Tvvkuz356f78j3UtqPVH0wQAqZOKauJPs9pgep\nI2IhsBCgsbFxgPyn6puqQaJhTHZ6ycxsICnlF+U2ABML5hvyZck2kqqBUWSD1b3Z1szMSqiUAbEc\nOF3SFEk1ZIPOS4vaLAWuyqcvAx6J7PhzKTBTUq2kKcDpwOMlrNXMzIqU7BRTPqZwLbCM7DLXRRGx\nWtJ8oCkilgJ3APfkg9CbyUKEvN19ZAPabcCflPMKJjOzSqT+GDAaCBobG6OpqancZZiZHVMkrYiI\nxtQ636zPzMySHBBmZpbkgDAzsyQHhJmZJR03g9SSWoD1R7CLscCmfirnWOf3oiu/H135/eh0PLwX\nkyJiXGrFcRMQR0pSU08j+ZXG70VXfj+68vvR6Xh/L3yKyczMkhwQZmaW5IDotLDcBQwgfi+68vvR\nld+PTsf1e+ExCDMzS/IRhJmZJTkgzMwsqeIDQtLFkp6VtFbSvHLXU06SJkr6d0lPS1ot6bPlrqnc\nJFVJekLSv5a7lnKTNFrSEknPSFoj6Z3lrqmcJP3P/N/JryV9V9KQctfU3yo6ICRVAQuAS4BpwCxJ\n08pbVVm1AX8WEdOAdwB/UuHvB8BngTXlLmKAuBX4t4h4I/B7VPD7ImkCcB3QGBFvIvtJg5nlrar/\nVXRAANOBtRGxLiL2AouBGWWuqWwiYmNErMynXyXrALr9FnilkNQAfAj4VrlrKTdJo4D3kP2GCxGx\nNyK2lreqsqsG6vJfwxwKvFzmevpdpQfEBOClgvlmKrhDLCRpMnA28Fh5KymrrwN/AbSXu5ABYArQ\nAtyZn3L7lqRh5S6qXCJiA/BV4EVgI7AtIn5c3qr6X6UHhCVIGg7cD/xpRGwvdz3lIOnDwO8iYkW5\naxkgqoFzgP8TEWcDO4CKHbOTNIbsbMMUYDwwTNKV5a2q/1V6QGwAJhbMN+TLKpakwWTh8O2I+H65\n6ymjc4FLJb1AdurxfEn3lreksmoGmiOi44hyCVlgVKoLgecjoiUi9gHfB95V5pr6XaUHxHLgdElT\nJNWQDTItLXNNZSNJZOeY10TE18pdTzlFxOcjoiEiJpP9f/FIRBx3nxB7KyJeAV6S9IZ80QVkvxlf\nqV4E3iFpaP7v5gKOw0H76nIXUE4R0SbpWmAZ2VUIiyJidZnLKqdzgU8AT0lalS/7XxHxozLWZAPH\nZ4Bv5x+m1gGzy1xP2UTEY5KWACvJrv57guPwthu+1YaZmSVV+ikmMzPrgQPCzMySHBBmZpbkgDAz\nsyQHhJmZJTkgzPpA0n5Jqwr++u3bxJImS/p1f+3P7EhV9PcgzA7Droh4S7mLMDsafARh1g8kvSDp\nK5KekvS4pNPy5ZMlPSLpSUk/kXRqvvwkSQ9I+lX+13GbhipJ38x/Z+DHkurK9qKs4jkgzPqmrugU\n0xUF67ZFxFnA7WR3ggW4DbgrIt4MfBv4+3z53wP/GRG/R3ZPo45v8J8OLIiIM4GtwEdL/HrMeuRv\nUpv1gaTXImJ4YvkLwPkRsS6/4eErEVEvaRNwSkTsy5dvjIixklqAhojYU7CPycBDEXF6Pv+XwOCI\n+HLpX5lZdz6CMOs/0cN0X+wpmN6PxwmtjBwQZv3nioLHX+TTj9L5U5T/A/hpPv0T4I/hwO9ejzpa\nRZr1lj+dmPVNXcGdbiH7jeaOS13HSHqS7ChgVr7sM2S/wvbnZL/I1nEH1M8CCyXNITtS+GOyXyYz\nGzA8BmHWD/IxiMaI2FTuWsz6i08xmZlZko8gzMwsyUcQZmaW5IAwM7MkB4SZmSU5IMzMLMkBYWZm\nSf8fsSwRWDw/mZMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9wdPxTI6aVP",
        "colab_type": "code",
        "outputId": "a0d2824c-cc4c-488a-bdd3-5049e494c9fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140367682672288 -->\n<g class=\"node\" id=\"node1\">\n<title>140367682672288</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_4_input: InputLayer</text>\n</g>\n<!-- 140367682671952 -->\n<g class=\"node\" id=\"node2\">\n<title>140367682671952</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_4: Dense</text>\n</g>\n<!-- 140367682672288&#45;&gt;140367682671952 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140367682672288-&gt;140367682671952</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140367682672008 -->\n<g class=\"node\" id=\"node3\">\n<title>140367682672008</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_5: Dense</text>\n</g>\n<!-- 140367682671952&#45;&gt;140367682672008 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140367682671952-&gt;140367682672008</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140367682698432 -->\n<g class=\"node\" id=\"node4\">\n<title>140367682698432</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_6: Dense</text>\n</g>\n<!-- 140367682672008&#45;&gt;140367682698432 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140367682672008-&gt;140367682698432</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjBH0Mhf9tDk",
        "colab_type": "code",
        "outputId": "3638106d-1e99-45c3-c364-95ac5eeb42dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}