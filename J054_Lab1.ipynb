{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J054_Lab1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narayananv10/DeepLearning/blob/master/J054_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LPdeJnLbhP5",
        "colab_type": "text"
      },
      "source": [
        "# Keras package in Python\n",
        "\n",
        "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
        "\n",
        "Use Keras if you need a deep learning library that:\n",
        "\n",
        "Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
        "Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
        "Runs seamlessly on CPU and GPU.\n",
        "Read the documentation at Keras.io.\n",
        "\n",
        "Keras is compatible with: Python 2.7-3.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5qa9OtRbyqO",
        "colab_type": "text"
      },
      "source": [
        "The core data structure of Keras is a **model**, a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. For more complex architectures, you should use the Keras functional API, which allows to build arbitrary graphs of layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6zlphu1bZIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here is the Sequential model:\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHysZQcdcAza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Stacking layers is as easy as .add():\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
        "model.add(Dense(units=1, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBcPLRoqd9iH",
        "colab_type": "text"
      },
      "source": [
        "# Compilation\n",
        "\n",
        "Before training a model, you need to configure the learning process, which is done via the compile method. It receives three arguments:\n",
        "\n",
        "An optimizer. This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class. \n",
        "\n",
        "\n",
        "A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function. \n",
        "\n",
        "A list of metrics. For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD6V0BrQcCNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Once your model looks good, configure its learning process with .compile():\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpokwhIudqU7",
        "colab_type": "text"
      },
      "source": [
        "# Specifying the input shape\n",
        "\n",
        "The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape. There are several possible ways to do this:\n",
        "\n",
        "Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or None entries, where None indicates that any positive integer may be expected). In input_shape, the batch dimension is not included.\n",
        "\n",
        "Some 2D layers, such as Dense, support the specification of their input shape via the argument input_dim, and some 3D temporal layers support the arguments input_dim and input_length.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q7KHVXVd47_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate dummy data\n",
        "import numpy as np\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(2, size=(1000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T2tgwU0e-fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the shape of inputs\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7wfi1JJfFtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the shape of labels\n",
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqYljCVFeLBj",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG96MZWdeP5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUSaXF22foxp",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 1: Build a Sequential model with two layers. \n",
        "\n",
        "Layer 1 is dense with 32 nodes and 'relu' activation function. Input dimension is 100.\n",
        "\n",
        "Layer 2 is dense with 10 nodes and 'softmax' activation function.\n",
        "\n",
        "Compile the model with optimizer 'rmsprop',             loss='categorical_crossentropy' and metrics=['accuracy']\n",
        "\n",
        "\n",
        "Generate dummy data using np.random.random 1000, 100 and dummy labels of 10 categories with size 1000,1\n",
        "\n",
        "\n",
        "## Convert labels to categorical one-hot encoding using below statement\n",
        "from keras.utils import to_categorical\n",
        "one_hot_labels = to_categorical(labels, num_classes=10)\n",
        "\n",
        "Finally, Train the model, iterating on the data in batches of 32 samples\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vfHQRZavn6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import utils as np_utils\n",
        "\n",
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvbkQ7pKzO8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "model.add(Dense(units=32, activation='relu', input_dim=100))\n",
        "model.add(Dense(units=10, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOWVH6T3veBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Once your model looks good, configure its learning process with .compile():\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhzDXIj4v0OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate dummy data\n",
        "import numpy as np\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(2, size=(1000, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDL5nqQ0vteY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert labels to categorical one-hot encoding\n",
        "one_hot_labels = np_utils.to_categorical(labels, num_classes=10)\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJrdnfAMfWbc",
        "colab_type": "text"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- The answer is below:\n",
        "from keras.utils import to_categorical\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=100))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate dummy data\n",
        "import numpy as np\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(10, size=(1000, 1))\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "one_hot_labels = to_categorical(labels, num_classes=10)\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, one_hot_labels, epochs=10, batch_size=32)\n",
        "\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVpe2f24jTIW",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 2: Building a Basic Keras Neural Network Sequential Model to classify MNIST dataset\n",
        "\n",
        "First we import package and a set hyperparameter and identify dataset variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl3kYpMSjqUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr-2yrEUjt5Q",
        "colab_type": "text"
      },
      "source": [
        "## Next is a function for outputting some simple (but useful) metadata of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koiwyv_Jj0Yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_summary(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"Summarize current state of dataset\"\"\"\n",
        "    print('Train images shape:', X_train.shape)\n",
        "    print('Train labels shape:', y_train.shape)\n",
        "    print('Test images shape:', X_test.shape)\n",
        "    print('Test labels shape:', y_test.shape)\n",
        "    print('Train labels:', y_train)\n",
        "    print('Test labels:', y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcHaDkegj-LU",
        "colab_type": "text"
      },
      "source": [
        "## Next we load our dataset (MNIST, using Keras' dataset utilities), and then use the function above to get some dataset metadata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeMLUCHHkBJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Check state of dataset\n",
        "data_summary(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQBMRuA5kKTQ",
        "colab_type": "text"
      },
      "source": [
        "To feed MNIST instances into a neural network, they need to be reshaped, from a 2 dimensional image representation to a single dimension sequence. We also convert our class vector to a binary matrix (using to_categorical). This is accomplished below, after which the same function defined above is called again in order to show the effects of our data reshaping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRwDGnB8kLpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# Check state of dataset\n",
        "data_summary(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ho-Gqe4elgoK"
      },
      "source": [
        "#Build a Sequential model of Neural Network with three dense layers.\n",
        "\n",
        "\n",
        "\n",
        "1.   Layer 1, 2 and 3 have 512, 256 and 10 nodes respectively. Activation function of first two layers is relu and final layer is softmax.\n",
        "2.   Compile model with optimizer='rmsprop',               loss='categorical_crossentropy' and metrics=['accuracy']\n",
        "3. Train the model with two additional parameters verbose=1 and validation_data=(X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FW3ygKD0FNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpeifKlC0Iih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGUI-4uq0JBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phu3Q6Nq0Nw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2ajV6BzmA8E",
        "colab_type": "text"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- The answer is below:\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R1P-fE9mlkV",
        "colab_type": "text"
      },
      "source": [
        "#Output a summary of the neural network we built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF62Moggmnye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Summary of neural network\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3r9ODkFmqwX",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF5PEZWPmtvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output network visualization\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XeWXc0ft6fO",
        "colab_type": "text"
      },
      "source": [
        "#Exercise: Train a Sequential Neural network on CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWjNVe9uCnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjXMCDsxuHAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SV6PPCHu6iy",
        "colab_type": "text"
      },
      "source": [
        "# Build sequential model \n",
        "\n",
        "\n",
        "\n",
        "1.   Sequential model with four layers having 1024,512,512,10 nodes respectively\n",
        "2.   Input shape = 3072\n",
        "3.   Activation of first three layers is relu and final is softmax\n",
        "4.   Compile model using loss='categorical_crossentropy', optimizer='adam' and metrics=['accuracy']\n",
        "5. Train model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t51-PrDOvK0R",
        "colab_type": "text"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!--\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=10,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxAE5ryN6cAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(X_train, Y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=10,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c81PL1bVxZRZ",
        "colab_type": "text"
      },
      "source": [
        "# Plot accuracy and loss after model is trained. \n",
        "\n",
        "(Caution: Will not work unless previous step is performed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptYUQKCWwTUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1JOX52A01Dc",
        "colab_type": "text"
      },
      "source": [
        "# Improving accuracy on Iris dataset\n",
        "\n",
        "\n",
        "\n",
        "1.   Find the accuracy of the below model\n",
        "2.   Improve accuracy by increasing layers, epochs, optimizer or loss metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN6DlpbYytgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "iris_data = load_iris()\n",
        "\t\n",
        "x = iris_data.data\n",
        "y_ = iris_data.target.reshape(-1, 1) # Convert data to a single column\n",
        "\n",
        "# One Hot encode the class labels\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y = encoder.fit_transform(y_)\n",
        "\n",
        "\n",
        "# Split the data for training and testing\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.01)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(10, input_shape=(4,), activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_x, train_y, verbose=2, batch_size=5, epochs=200)\n",
        "\n",
        "# Test on unseen data\n",
        "\n",
        "results = model.evaluate(test_x, test_y)\n",
        "\n",
        "print('Final test set loss: {:4f}'.format(results[0]))\n",
        "print('Final test set accuracy: {:4f}'.format(results[1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rkZZKV4yV9U",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl-88q4Mu-OH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<!--\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024, input_shape=(3072, )))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    # training\n",
        "    history = model.fit(X_train, Y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        nb_epoch=nb_epoch,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, Y_test))\n",
        "\n",
        "-->"
      ]
    }
  ]
}